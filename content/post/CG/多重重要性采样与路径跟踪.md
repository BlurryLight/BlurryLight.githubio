
---
title: "多重重要性采样与路径跟踪"
date: 2022-02-08T15:48:11+08:00
draft: false
# tags: [ "" ]
categories: [ "CG"]
# keywords: [ ""]
# lastmod: 2022-02-08T15:48:11+08:00
# CJKLanguage: Chinese, Japanese, Korean
isCJKLanguage: true
slug: "bd19f3eb"
toc: false
mermaid: false
# latex support
katex: true
markup: mmark
mmarktoc: true
---

Veach在其博士论文里详细阐述了MIS的理论[Multiple Importance Sampling](https://graphics.stanford.edu/courses/cs348b-03/papers/veach-chapter9.pdf)，并给出了一段简单的无偏性证明，但是其过于精简导致我一直没看懂无偏性的证明这一块，尤其是其无偏性的证明需要$$\sum_i\omega_i = 1$$这个条件，花了点时间想清楚。

# 多重重要性采样

Airguanz同学给出了渲染方程中应用MIS的[无偏性证明](https://airguanz.github.io/2018/10/15/multiple-importance-sampling.html),不过其符号比较复杂，花了点时间才看懂，因此自己写个笔记吧，也从自己的思路里出发。


## $$f(x)g(x)$$函数的估计
从PBRT中取[一小节内容](https://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/Importance_Sampling#MultipleImportanceSampling)作为例子。

假设两个已知形式函数$$f(x)$$和$$g(x)$$，要求的积分为$$\int f(x)g(x) dx$$,已知其重要性采样的pdf为$$p_f(x)$$和$$p_g(x)$$那么对其的多重重要性采样可以写作

$$
F = \frac{1}{n_{f}} \sum_{i=1}^{n_{f}} \frac{f\left(X_{i}\right) g\left(X_{i}\right) w_{f}\left(X_{i}\right)}{p_{f}\left(X_{i}\right)}+\frac{1}{n_{g}} \sum_{j=1}^{n_{g}} \frac{f\left(Y_{j}\right) g\left(Y_{j}\right) w_{g}\left(Y_{j}\right)}{p_{g}\left(Y_{j}\right)} \labeltag{1}
$$

假设抽样次数相同$$n_f = n_g = n$$,那么$$n$$可以提出来，我们只研究单次的采样

$$
F = \frac{1}{n}\sum_{i=1}^{n}( \frac{f\left(X_{i}\right) g\left(X_{i}\right) w_{f}\left(X_{i}\right)}{p_{f}\left(X_{i}\right)} + \frac{f\left(Y_{j}\right) g\left(Y_{j}\right) w_{g}\left(Y_{j}\right)}{p_{g}\left(Y_{j}\right)}) \labeltag{2}
$$

一种权重$$\omega_s$$的计算方式可以写作，veach指出$$\beta = 2$$ 的时候效果不错，不过也可以记为$$\beta = 1$$，不影响无偏性

$$
w_{s}(x)=\frac{\left(n_{s} p_{s}(x)\right)^{\beta}}{\sum_{i}\left(n_{i} p_{i}(x)\right)^{\beta}}
$$

那么上述公式中的第一项可以转写为，

$$
\frac{f(X) g(X) w_{f}(X)}{p_{f}(X)}=\frac{f(X) g(X) n_{f} p_{f}(X)}{p_{f}(X)\left(n_{f} p_{f}(X)+n_{g} p_{g}(X)\right)}=\frac{f(X) g(X) n_{f}}{n_{f} p_{f}(X)+n_{g} p_{g}(X)}
$$

其中$$nf,ng$$是从分布$$pdf_f$$，$$pdf_g$$中采样次数，由于路径追踪中我们每次只生成一根光线，所以其值可以都令为1。
整理为

$$
\frac{f(X) g(X)} { p_{f}(X)+ p_{g}(X)} + \frac{f(Y) g(Y)} { p_{f}(Y)+ p_{g}(Y)}
$$

这样当$$p_f(x)$$的值很小的时候，$$p_g(x)$$可能比较大，避免了大方差的引入。

## 无偏性证明


对式子$$\eqref{2}$$的多重重要性采样估计$$F$$求期望

$$
E(F) = 
\frac{1}{n}\sum_1^n (E(\frac{f(X_i) g(X_i)} { p_{f}(X_i)+ p_{g}(X_i)}) + E(\frac{f(Y_i) g(Y_i)} { p_{f}(Y_i)+ p_{g}(Y_i)}))
$$

对连续随机变量求数学期望的式子为$$E[F] = \int f(x) p(x) dx $$,上面的式子带入下来
单独拿出来第一项，其变量`x`是从分布$$p_f(x)$$中取出来的，因此其积分式子中应该乘以$$p_f(x)$$,期望为

$$
E_1 = E(\frac{f(X_i) g(X_i)} { p_{f}(X_i)+ p_{g}(X_i)}) = \int \frac{f(x) g(x)} { p_{f}(x)+ p_{g}(x)}  * p_f(x) dx
$$

同样后面的可以写作

$$
E_2 = \int \frac{f(y) g(y)} { p_{f}(y)+ p_{g}(y)}  * p_g(y) dy
$$

两个期望的分子均包含$$f()g()$$，假设函数$$f()$$和$$g()$$在函数定义域外的值为0，则对$$f()g()$$积分的积分区间为两个函数的定义域的交集(因为交集外$$f()g()$$必然有一项为0)

因此则两个期望积分式的积分区间相同，对于任意一个`x`必然能找到和其相等的`y`，所以在积分内其$x,y$符号可以互换，因此积分的累加可以写作累加和的积分

$$
\begin{aligned}
E(F) = E_1 + E _2 &= \int \frac{f(y) g(y)} { p_{f}(y)+ p_{g}(y)}  * p_g(y) dy + \frac{f(y) g(y)} { p_{f}(y)+ p_{g}(y)}  * p_f(y) dy \\
&=\int \frac{f(y) g(y)} { \color{red}{\cancel{p_{f}(y)+ p_{g}(y)}}}  * \color{red}{\cancel{(p_g(y) + p_f(y))}}  \color{black}{dy} \\
&= \int f(y)g(y)  dy
\end{aligned}
$$

由此证明其为无偏估计